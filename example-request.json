{
  "input": {
    "workflow": {
      "3": {
        "inputs": {
          "seed": 309876361212004,
          "steps": 20,
          "cfg": 2.5,
          "sampler_name": "euler",
          "scheduler": "simple",
          "denoise": 1,
          "model": [
            "73",
            0
          ],
          "positive": [
            "6",
            0
          ],
          "negative": [
            "7",
            0
          ],
          "latent_image": [
            "58",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "6": {
        "inputs": {
          "text": "a beautiful naked blond woman with small breasts stands, knees bent, legs apart, standing over the torso of a man with an erect penis. \ndr3am",
          "clip": [
            "38",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Positive Prompt)"
        }
      },
      "7": {
        "inputs": {
          "text": "bad anatomy, defoemd. ",
          "clip": [
            "38",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Negative Prompt)"
        }
      },
      "8": {
        "inputs": {
          "samples": [
            "3",
            0
          ],
          "vae": [
            "39",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAEDecode"
        }
      },
      "37": {
        "inputs": {
          "filename": "qwen_image_fp8_e4m3fn.safetensors"
        },
        "class_type": "UNETLoader",
        "_meta": {
          "title": "UNETLoader"
        }
      },
      "38": {
        "inputs": {
          "filename": "qwen_2.5_vl_7b_fp8_scaled.safetensors"
        },
        "class_type": "CLIPLoader",
        "_meta": {
          "title": "CLIPLoader"
        }
      },
      "39": {
        "inputs": {
          "filename": "qwen_image_vae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "VAELoader"
        }
      },
      "58": {
        "inputs": {
          "width": 240,
          "height": 240,
          "batch_size": 1
        },
        "class_type": "EmptySD3LatentImage",
        "_meta": {
          "title": "EmptySD3LatentImage"
        }
      },
      "60": {
        "inputs": {
          "filename_prefix": "Qwen/qwen",
          "images": [
            "8",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "SaveImage"
        }
      },
      "66": {
        "inputs": {
          "value": 3.1
        },
        "class_type": "ModelSamplingAuraFlow",
        "_meta": {
          "title": "ModelSamplingAuraFlow"
        }
      },
      "73": {
        "inputs": {
          "filename": "Qwen-Image-Lightning-4steps-V2.0.safetensors",
          "model": [
            "37",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      }
    }
  }
}